---
---

@article{chen-etal-2019-qtuna,
    title = "Out-of-domain Detection for Natural Language Understanding in Dialog Systems",
    author    = {Zheng, Yinhe and
               Chen, Guanyi and
               Huang, Minlie},
  journal   = {IEEE/ACM Transactions Audio, Speech, and Language Processing},
  year      = {2020},
  arxiv       = {1909.03862},
  abstract = "Natural Language Understanding (NLU) is a vital component of dialogue systems, and its ability to detect Out-of-Domain (OOD) inputs is critical in practical applications, since the acceptance of the OOD input that is unsupported by the current system may lead to catastrophic failure. However, most existing OOD detection methods rely heavily on manually labeled OOD samples and cannot take full advantage of unlabeled data. This limits the feasibility of these models in practical applications. 

In this paper, we propose a novel model to generate high-quality pseudo OOD samples that are akin to IN-Domain (IND) input utterances and thereby improves the performance of OOD detection. To this end, an autoencoder is trained to map an input utterance into a latent code. Moreover, the codes of IND and OOD samples are trained to be indistinguishable by utilizing a generative adversarial network. To provide more supervision signals, an auxiliary classifier is introduced to regularize the generated OOD samples to have indistinguishable intent labels. Experiments show that these pseudo OOD samples generated by our model can be used to effectively improve OOD detection in NLU. Besides, we also demonstrate that the effectiveness of these pseudo OOD data can be further improved by efficiently utilizing unlabeled data.",
}


@inproceedings{chen-etal-2019-qtuna,
    title = "{QTUNA}: A Corpus for Understanding How Speakers Use Quantification",
    author = "Chen, Guanyi  and
      van Deemter, Kees  and
      Pagliaro, Silvia  and
      Smalbil, Louk  and
      Lin, Chenghua",
    booktitle = "INLG 2019, Tokyo",
    month = oct # "{--}" # nov,
    year = "2019",
    address = "Tokyo, Japan",
    publisher = "Association for Computational Linguistics",
    pdf = "https://www.aclweb.org/anthology/W19-8616.pdf",
    supp = "https://www.aclweb.org/anthology/attachments/W19-8616.Supplementary_Attachment.pdf",
    data = "https://github.com/a-quei/qtuna",
    doi = "10.18653/v1/W19-8616",
    pages = "124--129",
    abstract = "A prominent strand of work in formal semantics investigates the ways in which human languages quantify over the elements of a set, as when we say {``}All A are B{''}, {``}All except two A are B{''}, {``}Only a few of the A are B{''} and so on. Our aim is to build Natural Language Generation algorithms that mimic humans{'} use of quantified expressions. To inform these algorithms, we conducted on a series of elicitation experiments in which human speakers were asked to perform a linguistic task that invites the use of quantified expressions. We discuss how these experiments were conducted and what corpora they gave rise to. We conduct an informal analysis of the corpora, and offer an initial assessment of the challenges that these corpora pose for Natural Language Generation.",
}

@inproceedings{chen-etal-2019-generating,
    title = "Generating Quantified Descriptions of Abstract Visual Scenes",
    author = "Chen, Guanyi  and
      van Deemter, Kees  and
      Lin, Chenghua",
    booktitle = "INLG 2019, Tokyo",
    month = oct # "{--}" # nov,
    year = "2019",
    address = "Tokyo, Japan",
    publisher = "Association for Computational Linguistics",
    pdf = "https://www.aclweb.org/anthology/W19-866.pdf",
    code = "https://github.com/a-quei/quantified-description-generation",
    supp = "https://www.aclweb.org/anthology/attachments/W19-8667.Supplementary_Attachment.pdf",
    doi = "10.18653/v1/W19-8667",
    pages = "529--539",
    abstract = "Quantified expressions have always taken up a central position in formal theories of meaning and language use. Yet quantified expressions have so far attracted far less attention from the Natural Language Generation community than, for example, referring expressions. In an attempt to start redressing the balance, we investigate a recently developed corpus in which quantified expressions play a crucial role; the corpus is the result of a carefully controlled elicitation experiment, in which human participants were asked to describe visually presented scenes. Informed by an analysis of this corpus, we propose algorithms that produce computer-generated descriptions of a wider class of visual scenes, and we evaluate the descriptions generated by these algorithms in terms of their correctness, completeness, and human-likeness. We discuss what this exercise can teach us about the nature of quantification and about the challenges posed by the generation of quantified expressions.",
}

@inproceedings{chen-yao-2019-closer,
    title = "A Closer Look at Recent Results of Verb Selection for Data-to-Text {NLG}",
    author = "Chen, Guanyi  and
      Yao, Jin-Ge",
    booktitle = "INLG 2019, Tokyo",
    month = oct # "{--}" # nov,
    year = "2019",
    address = "Tokyo, Japan",
    publisher = "Association for Computational Linguistics",
    pdf = "https://www.aclweb.org/anthology/W19-8622.pdf",
    supp = "https://www.aclweb.org/anthology/attachments/W19-8622.Supplementary_Attachment.pdf",
    doi = "10.18653/v1/W19-8622",
    pages = "158--163",
    abstract = "Automatic natural language generation systems need to use the contextually-appropriate verbs when describing different kinds of facts or events, which has triggered research interest on verb selection for data-to-text generation. In this paper, we discuss a few limitations of the current task settings and the evaluation metrics. We also provide two simple, efficient, interpretable baseline approaches for statistical selection of trend verbs, which give a strong performance on both previously used evaluation metrics and our new evaluation.",
}

@inproceedings{DBLP:journals/corr/abs-1901-09672,
  author    = {Zheng, Yinhe and
               Chen, Guanyi and
               Huang, Minlie and
               Liu, Song and
               Zhu, Xuan},
  title     = {Persona-aware Dialogue Generation with Enriched Profile},
  booktitle   = {NeurIPS 2019 on Conversational AI Workshop, Vancouver},
  year      = {2019},
  arxiv       = {1901.09672},
  abstract = "Endowing a dialogue system with particular persona is essential to deliver more human-like conversations. However, due to the difficulties of embodying personalities in natural language, this problem is still far from well studied. This paper proposes a novel task of generating dialogue responses conditioned on explicit personal profiles with rich attributes. A dataset is constructed to facilitate the proposed task and a persona-aware dialogue generation model is also introduced. In this model, a structured personal profile (in key-value pairs) is transformed and composed into a representation vector using a persona fusion module, and several different fusion methods are tested. Two techniques, namely {\it persona-aware attention} and persona-aware bias, are devised to capture and incorporate various persona attributes in the decoding process. Experiments and case studies demonstrate that our model is able to address proper attributes in different contexts.",
}


@inproceedings{li-etal-2019-dual,
    title = "A Dual-Attention Hierarchical Recurrent Neural Network for Dialogue Act Classification",
    author = "Li, Ruizhe  and
      Lin, Chenghua  and
      Collinson, Matthew  and
      Li, Xiao  and
      Chen, Guanyi",
    booktitle = "CoNLL 2019, Hong Kong, China",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pdf = "https://www.aclweb.org/anthology/K19-1036.pdf",
    doi = "10.18653/v1/K19-1036",
    pages = "383--392",
    abstract = "Recognising dialogue acts (DA) is important for many natural language processing tasks such as dialogue generation and intention recognition. In this paper, we propose a dual-attention hierarchical recurrent neural network for DA classification. Our model is partially inspired by the observation that conversational utterances are normally associated with both a DA and a topic, where the former captures the social act and the latter describes the subject matter. However, such a dependency between DAs and topics has not been utilised by most existing systems for DA classification. With a novel dual task-specific attention mechanism, our model is able, for utterances, to capture information about both DAs and topics, as well as information about the interactions between them. Experimental results show that by modelling topic as an auxiliary task, our model can significantly improve DA classification, yielding better or comparable performance to the state-of-the-art method on three public datasets.",
}


@inproceedings{chen-etal-2018-simplenlg,
    title = "{S}imple{NLG}-{ZH}: a Linguistic Realisation Engine for {M}andarin",
    author = "Chen, Guanyi  and
      van Deemter, Kees  and
      Lin, Chenghua",
    booktitle = "INLG 2018, Tilburg",
    month = nov,
    year = "2018",
    address = "Tilburg University, The Netherlands",
    publisher = "Association for Computational Linguistics",
    pdf = "https://www.aclweb.org/anthology/W18-6506.pdf",
    doi = "10.18653/v1/W18-6506",
    code = "https://github.com/a-quei/simplenlg-zh",
    pages = "57--66",
    abstract = "We introduce SimpleNLG-ZH, a realisation engine for Mandarin that follows the software design paradigm of SimpleNLG (Gatt and Reiter, 2009). We explain the core grammar (morphology and syntax) and the lexicon of SimpleNLG-ZH, which is very different from English and other languages for which SimpleNLG engines have been built. The system was evaluated by regenerating expressions from a body of test sentences and a corpus of human-authored expressions. Human evaluation was conducted to estimate the quality of regenerated sentences.",
}

@inproceedings{chen-etal-2018-modelling,
    title = "Modelling Pro-drop with the Rational Speech Acts Model",
    author = "Chen, Guanyi  and
      van Deemter, Kees  and
      Lin, Chenghua",
    booktitle = "INLG 2018, Tilburg",
    month = nov,
    year = "2018",
    address = "Tilburg University, The Netherlands",
    publisher = "Association for Computational Linguistics",
    pdf = "https://www.aclweb.org/anthology/W18-6519.pdf",
    doi = "10.18653/v1/W18-6519",
    pages = "159--164",
    abstract = "We extend the classic Referring Expressions Generation task by considering zero pronouns in {``}pro-drop{''} languages such as Chinese, modelling their use by means of the Bayesian Rational Speech Acts model (Frank and Goodman, 2012). By assuming that highly salient referents are most likely to be referred to by zero pronouns (i.e., pro-drop is more likely for salient referents than the less salient ones), the model offers an attractive explanation of a phenomenon not previously addressed probabilistically.",
}

@inproceedings{mao-etal-2018-abdn,
    title = "{ABDN} at {S}em{E}val-2018 Task 10: Recognising Discriminative Attributes using Context Embeddings and {W}ord{N}et",
    author = "Mao, Rui  and
      Chen, Guanyi  and
      Li, Ruizhe  and
      Lin, Chenghua",
    booktitle = "NAACL 2018 on SemEval Workshop, New Orleans",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    pdf = "https://www.aclweb.org/anthology/S18-1169.pdf",
    doi = "10.18653/v1/S18-1169",
    pages = "1017--1021",
    abstract = "This paper describes the system that we submitted for SemEval-2018 task 10: capturing discriminative attributes. Our system is built upon a simple idea of measuring the attribute word{'}s similarity with each of the two semantically similar words, based on an extended word embedding method and WordNet. Instead of computing the similarities between the attribute and semantically similar words by using standard word embeddings, we propose a novel method that combines word and context embeddings which can better measure similarities. Our model is simple and effective, which achieves an average F1 score of 0.62 on the test set.",
}


