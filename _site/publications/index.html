<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Guanyi Chen | publications</title>
  <meta name="description" content="I am a PhD Candidate at Utrecht University&#44; working on Natural Language Generation. I am supervised by Prof. Kees van Deemter and Dr. Chenghua Lin.
">

  <link rel="shortcut icon" href="http://localhost:4000/assets/img/favicon.ico">

  <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
  <link rel="canonical" href="http://localhost:4000/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Guanyi</strong> Chen
    </span>
    

    <nav class="site-nav">

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="http://localhost:4000/">about</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="http://localhost:4000/blog/">blog</a>-->

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="http://localhost:4000/publications/">publications</a>
          
        
          
            <a class="page-link" href="http://localhost:4000/resources/">resources</a>
          
        
          
            <a class="page-link" href="http://localhost:4000/thesis/">thesis</a>
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="http://localhost:4000/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description">A update-to-date list of my publication can be found in my <a href="https://scholar.google.com/citations?user=wt7-UUYAAAAJ&hl=en"><u>Google Scholar</u></a> page. </br> (* indicates equal contribution)</h5>
  </header>

  <article class="post-content publications clearfix">
    
<h3 class="year">2023</h3>
<ol class="bibliography"><li>

<div id="chen-van-deemter-2023-varieties">
  
    <span class="title">Varieties of specification: Redefining over- and under-specification for an enhanced understanding of referring expressions</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          and
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Pragmatics</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="same-et-al-2022-assessing">
  
    <span class="title">Models of reference production: How do they withstand the test of time?</span>
    <span class="author">
      
        
        
          
          
            
              <a href="https://fsame.github.io/" target="_blank">Fahime Same</a>,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          and
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2023, Prague</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="chen-et-al-2023-coref">
  
    <span class="title">A Multi-task Learning Model for Gold-two-mention Co-reference Resolution</span>
    <span class="author">
      
        
        
          
          
            
              Ruicheng Liu,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://maorui.wixsite.com/homepage" target="_blank">Rui Mao</a>,
            
          
        
      
        
        
          
          and
          
          
            
              Erik Cambria
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In IJCNN 2023, Queensland</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="chen-et-al-2023-copmputational">
  
    <span class="title">Computational Modelling of Quantifier Use: Elicitation Experiments, Models, and Evaluation</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          and
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Artificial Intelligence Research</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="chen-et-al-2023-neural">
  
    <span class="title">Neural Referential Form Selection: Generalisability and Interpretability</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://fsame.github.io/" target="_blank">Fahime Same</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Computer Speech and Language</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li></ol>

<h3 class="year">2022</h3>
<ol class="bibliography"><li>

<div id="chen-et-al-2022-assessing">
  
    <span class="title">Assessing Neural Referential Form Selectors on a Realistic Multilingual Dataset</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://fsame.github.io/" target="_blank">Fahime Same</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In AACL 2022 on Eval4NLP Workshop, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="chen-van-deemter-2022-understanding">
  
    <span class="title">Understanding the Use of Quantifiers in Mandarin</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          and
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In AACL-Findings 2022, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
  
    [<a href="http://arxiv.org/abs/2209.11977" target="_blank">arXiv</a>]
  
  
  
    [<a href="https://aclanthology.org/2022.findings-aacl.7.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="Baig-etal-2022-drivingbeacon">
  
    <span class="title">DrivingBeacon: Driving Behaviour Change Support System Considering Mobile Use and Geo-information</span>
    <span class="author">
      
        
        
          
          
            
              Jawwad Baig,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://ehudreiter.com/" target="_blank">Ehud Reiter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2022 on NLG4Healthcare Workshop, Maine</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
  
  
  
    [<a href="https://aclanthology.org/2022.nlg4health-1.1.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="chen2022computational">
  
    <span class="title">Computational Generation of Chinese Noun Phrases</span>
    <span class="author">
      
        
        
          
          
          
            <em>Guanyi Chen</em>
          
        
      
    </span>

    <span class="periodical">
    
      <em>PhD Thesis, Utrecht University</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
  
  
  
    [<a href="https://a-quei.github.io/assets/file/thesis-final.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="same-etal-2022-is">
  
    <span class="title">Non-neural Models can Matter: a Re-evaluation of Neural Referring Expression Generation Systems</span>
    <span class="author">
      
        
        
          
          
            
              Fahime Same*,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen*</em>,
          
        
      
        
        
          
          and
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In ACL 2022, Dublin</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2203.08274" target="_blank">arXiv</a>]
  
  
  
    [<a href="https://aclanthology.org/2022.acl-long.380.pdf" target="_blank">PDF</a>]
  
  
  
    [<a href="https://github.com/a-quei/neuralreg-re-evaluation" target="_blank">Data</a>]
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In recent years, neural models have often outperformed rule-based and classic Machine Learning approaches in NLG. These classic approaches are now often disregarded, for example when new neural models are evaluated. We argue that they should not be overlooked, since, for some tasks, well-designed non-neural approaches achieve better performance than neural ones. In this paper, the task of generating referring expressions in linguistic context is used as an example. We examined two very different English datasets (WEBNLG and WSJ), and evaluated each algorithm using both automatic and human evaluations. Overall, the results of these evaluations suggest that rule-based systems with simple rule sets achieve on-par or better performance on both datasets compared to state-of-the-art neural REG systems. In the case of the more realistic dataset, WSJ, a machine learning-based system with well-designed linguistic features performed best. We hope that our work can encourage researchers to consider non-neural models in future.</p>
  </span>
  
</div>
</li>
<li>

<div id="zheng2021mmchat">
  
    <span class="title">MMChat: Multi-Modal Chat Dataset on Social Media</span>
    <span class="author">
      
        
        
          
          
            
              Yinhe Zheng*,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen*</em>,
          
        
      
        
        
          
          
            
              Xin Liu,
            
          
        
      
        
        
          
          and
          
          
            
              Jian Sun
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In LREC 2022, Marseille</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2108.07154" target="_blank">arXiv</a>]
  
  
  
    [<a href="https://aclanthology.org/2022.lrec-1.621.pdf" target="_blank">PDF</a>]
  
  
  
    [<a href="https://paperswithcode.com/paper/mmchat-multi-modal-chat-dataset-on-social" target="_blank">Data</a>]
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Incorporating multi-modal contexts in conversation is an important step for developing more engaging dialogue systems. In this work, we explore this direction by introducing MMChat: a large scale multi-modal dialogue corpus (32.4M raw dialogues and 120.84K filtered dialogues). Unlike previous corpora that are crowd-sourced or collected from fictitious movies, MMChat contains image-grounded dialogues collected from real conversations on social media, in which the sparsity issue is observed. Specifically, image-initiated dialogues in common communications may deviate to some non-image-grounded topics as the conversation proceeds. We develop a benchmark model to address this issue in dialogue generation tasks by adapting the attention routing mechanism on image features. Experiments demonstrate the usefulness of incorporating image features and the effectiveness in handling the sparsity of image features.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2021</h3>
<ol class="bibliography"><li>

<div id="chen-etal-2021-what">
  
    <span class="title">What can Neural Referential Form Selectors Learn?</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen*</em>,
          
        
      
        
        
          
          
            
              Fahime Same*,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2021, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2108.06806" target="_blank">arXiv</a>]
  
  
  
  
  
  
  
  
    [<a href="https://github.com/a-quei/probe-neuralreg" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Despite achieving encouraging results, neural Referring Expression Generation models are often thought to lack transparency. We probed neural Referential Form Selection (RFS) models to find out to what extent the linguistic features influencing the RE form are learnt and captured by state-of-the-art RFS models. The results of 8 probing tasks show that all the defined features were learnt to some extent. The probing tasks pertaining to referential status and syntactic position exhibited the highest performance. The lowest performance was achieved by the probing models designed to predict discourse structure properties beyond the sentence level.</p>
  </span>
  
</div>
</li>
<li>

<div id="zeng-etal-2021-affective">
  
    <span class="title">Affective Decoding for Empathetic Response Generation</span>
    <span class="author">
      
        
        
          
          
            
              Chengkun Zeng,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>,
            
          
        
      
        
        
          
          
            
              <a href="https://ruizheliuoa.github.io/" target="_blank">Ruizhe Li</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://zhigang-chen.github.io/index.html" target="_blank">Zhigang Chen</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2021, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2108.08102" target="_blank">arXiv</a>]
  
  
  
  
  
  
  
  
    [<a href="https://github.com/zenggo/affective-decoding-4-empathetic-dialog" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Understanding speaker’s feelings and producing appropriate responses with emotion connection is a key communicative skill for empathetic dialogue systems. In this paper, we propose a simple technique called Affective Decoding for empathetic response generation. Our method can effectively incorporate emotion signals during each decoding step, and can additionally be augmented with an auxiliary dual emotion encoder, which learns separate embeddings for the speaker and listener given the emotion base of the dialogue. Extensive empirical studies show that our models are perceived to be more empathetic by human evaluations, in comparison to several strong mainstream methods for empathetic responding.</p>
  </span>
  
</div>
</li>
<li>

<div id="jani-etal-2021-using">
  
    <span class="title">Using BERT for choosing classifiers in Mandarin</span>
    <span class="author">
      
        
        
          
          
            
              Jani Jarnfors,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>,
            
          
        
      
        
        
          
          and
          
          
            
              Rint Sybesma
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2021, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
</div>
</li>
<li>

<div id="peng-et-al-2021-highly">
  
    <span class="title">Highly Efficient Knowledge Graph Embedding Learning with Orthogonal Procrustes Analysis</span>
    <span class="author">
      
        
        
          
          
            
              <a href="https://xutan.me/" target="_blank">Xutan Peng</a>,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://staffwww.dcs.shef.ac.uk/people/M.Stevenson/" target="_blank">Mark Stevenson</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In NAACL 2021, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2104.04676" target="_blank">arXiv</a>]
  
  
  
  
  
  
  
  
    [<a href="https://github.com/Pzoom522/ProcrustEs-KGE" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Knowledge Graph Embeddings (KGEs) have been intensively explored in recent years due to their promise for a wide range of applications. However, existing studies focus on improving the final model performance without acknowledging the computational cost of the proposed approaches, in terms of execution time and environmental impact. This paper proposes a simple yet effective KGE framework which can reduce the training time and carbon footprint by orders of magnitudes compared with state-of-the-art approaches, while producing competitive performance. We highlight three technical innovations: full batch learning via relational matrices, closed-form Orthogonal Procrustes Analysis for KGEs, and non-negative-sampling training. In addition, as the first KGE method whose entity embeddings also store full relation information, our trained models encode rich semantics and are highly interpretable. Comprehensive experiments and ablation studies involving 13 strong baselines and two standard datasets verify the effectiveness and efficiency of our algorithm.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2020</h3>
<ol class="bibliography"><li>

<div id="chen-etal-2020-listeners">
  
    <span class="title">Listener’s Social Identity Matters in Personalised Response Generation</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://scholar.google.nl/citations?user=FhU-R7kAAAAJ&amp;hl=en" target="_blank">Yinhe Zheng</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://www.uu.nl/staff/YDu?t=0" target="_blank">Yupei Du</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2020, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2010.14342" target="_blank">arXiv</a>]
  
  
  
    [<a href="https://www.aclweb.org/anthology/2020.inlg-1.26.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Personalised response generation enables generating human-like responses by means of assigning the generator a social identity. However, pragmatics theory suggests that human beings adjust the way of speaking based on not only who they are but also whom they are talking to. In other words, when modelling personalised dialogues, it might be favourable if we also take the listener’s social identity into consideration. To validate this idea, we use gender as a typical example of a social variable to investigate how the listener’s identity influences the language used in Chinese dialogues on social media. Also, we build personalised generators. The experiment results demonstrate that the listener’s identity indeed matters in the language use of responses and that the response generator can capture such differences in language use. More interestingly, by additionally modelling the listener’s identity, the personalised response generator performs better in its own identity.</p>
  </span>
  
</div>
</li>
<li>

<div id="chen-van-deemter-2020-lessons">
  
    <span class="title">Lessons from Computational Modelling of Reference Production in Mandarin and English</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          and
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2020, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2011.07398" target="_blank">arXiv</a>]
  
  
  
    [<a href="https://www.aclweb.org/anthology/2020.inlg-1.33.pdf" target="_blank">PDF</a>]
  
  
  
    [<a href="https://github.com/a-quei/mtuna-annotated" target="_blank">Data</a>]
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Referring expression generation (REG) algorithms offer computational models of the production of referring expressions. In earlier work, a corpus of referring expressions (REs) in Mandarin was introduced. In the present paper, we annotate this corpus, evaluate classic REG algorithms on it, and compare the results with earlier results on the evaluation of REG for English referring expressions. Next, we offer an in-depth analysis of the corpus, focusing on issues that arise from the grammar of Mandarin. We discuss shortcomings of previous REG evaluations that came to light during our investigation and we highlight some surprising results. Perhaps most strikingly, we found a much higher proportion of under-specified expressions than previous studies had suggested, not just in Mandarin but in English as well.</p>
  </span>
  
</div>
</li>
<li>

<div id="van-miltenburg-etal-2020-gradations">
  
    <span class="title">Gradations of Error Severity in Automatic Image Descriptions</span>
    <span class="author">
      
        
        
          
          
            
              <a href="https://www.emielvanmiltenburg.nl/" target="_blank">Emiel van Miltenburg</a>,
            
          
        
      
        
        
          
          
            
              Wei-Ting Lu,
            
          
        
      
        
        
          
          
            
              <a href="http://www.emielkrahmer.nl/" target="_blank">Emiel Krahmer</a>,
            
          
        
      
        
        
          
          
            
              <a href="https://staff.um.edu.mt/albert.gatt/" target="_blank">Albert Gatt</a>,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://www.aclweb.org/anthology/people/l/lin-li/" target="_blank">Lin Li</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2020, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/2020.inlg-1.45.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Earlier research has shown that evaluation metrics based on textual similarity (e.g., BLEU, CIDEr, Meteor) do not correlate well with human evaluation scores for automatically generated text. We carried out an experiment with Chinese speakers, where we systematically manipulated image descriptions to contain different kinds of errors. Because our manipulated descriptions form minimal pairs with the reference descriptions, we are able to assess the impact of different kinds of errors on the perceived quality of the descriptions. Our results show that different kinds of errors elicit significantly different evaluation scores, even though all erroneous descriptions differ in only one character from the reference descriptions. Evaluation metrics based solely on textual similarity are unable to capture these differences, which (at least partially) explains their poor correlation with human judgments. Our work provides the foundations for future work, where we aim to understand why different errors are seen as more or less severe.</p>
  </span>
  
</div>
</li>
<li>

<div id="li-etal-2020-improving-variational">
  
    <span class="title">Improving Variational Autoencoder for Text Modelling with Timestep-Wise Regularisation</span>
    <span class="author">
      
        
        
          
          
            
              <a href="https://ruizheliuoa.github.io/" target="_blank">Ruizhe Li</a>,
            
          
        
      
        
        
          
          
            
              <a href="https://scholar.google.nl/citations?user=ZxQFX5EAAAAJ&amp;hl=en" target="_blank">Xiao Li</a>,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          and
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In COLING 2020, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2011.01136" target="_blank">arXiv</a>]
  
  
  
    [<a href="https://www.aclweb.org/anthology/2020.coling-main.216.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The Variational Autoencoder (VAE) is a popular and powerful model applied to text modelling to generate diverse sentences. However, an issue known as posterior collapse (or KL loss vanishing) happens when the VAE is used in text modelling, where the approximate posterior collapses to the prior, and the model will totally ignore the latent variables and be degraded to a plain language model during text generation. Such an issue is particularly prevalent when RNN-based VAE models are employed for text modelling. In this paper, we propose a simple, generic architecture called Timestep-Wise Regularisation VAE (TWR-VAE), which can effectively avoid posterior collapse and can be applied to any RNN-based VAE models. The effectiveness and versatility of our model are demonstrated in different tasks, including language modelling and dialogue response generation.</p>
  </span>
  
</div>
</li>
<li>

<div id="li-etal-2020-dgst">
  
    <span class="title">DGST: a Dual-Generator Network for Text Style Transfer</span>
    <span class="author">
      
        
        
          
          
            
              <a href="https://scholar.google.nl/citations?user=ZxQFX5EAAAAJ&amp;hl=en" target="_blank">Xiao Li</a>,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://ruizheliuoa.github.io/" target="_blank">Ruizhe Li</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In EMNLP 2020, Online</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/2010.14557" target="_blank">arXiv</a>]
  
  
  
    [<a href="https://www.aclweb.org/anthology/2020.emnlp-main.578.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
    [<a href="https://xiao.ac/proj/dgst" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We propose DGST, a novel and simple Dual-Generator network architecture for text Style Transfer. Our model employs two generators only, and does not rely on any discriminators or parallel corpus for training. Both quantitative and qualitative experiments on the Yelp and IMDb datasets show that our model gives competitive performance compared to several strong baselines with more complicated architecture designs.</p>
  </span>
  
</div>
</li>
<li>

<div id="zheng-etal-2020-ood">
  
    <span class="title">Out-of-domain Detection for Natural Language Understanding in Dialog Systems</span>
    <span class="author">
      
        
        
          
          
            
              <a href="https://scholar.google.nl/citations?user=FhU-R7kAAAAJ&amp;hl=en" target="_blank">Yinhe Zheng</a>,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          and
          
          
            
              <a href="http://coai.cs.tsinghua.edu.cn/hml/" target="_blank">Minlie Huang</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE/ACM Transactions Audio, Speech, and Language Processing</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/1909.03862" target="_blank">arXiv</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Natural Language Understanding (NLU) is a vital component of dialogue systems, and its ability to detect Out-of-Domain (OOD) inputs is critical in practical applications, since the acceptance of the OOD input that is unsupported by the current system may lead to catastrophic failure. However, most existing OOD detection methods rely heavily on manually labeled OOD samples and cannot take full advantage of unlabeled data. This limits the feasibility of these models in practical applications. 

In this paper, we propose a novel model to generate high-quality pseudo OOD samples that are akin to IN-Domain (IND) input utterances and thereby improves the performance of OOD detection. To this end, an autoencoder is trained to map an input utterance into a latent code. Moreover, the codes of IND and OOD samples are trained to be indistinguishable by utilizing a generative adversarial network. To provide more supervision signals, an auxiliary classifier is introduced to regularize the generated OOD samples to have indistinguishable intent labels. Experiments show that these pseudo OOD samples generated by our model can be used to effectively improve OOD detection in NLU. Besides, we also demonstrate that the effectiveness of these pseudo OOD data can be further improved by efficiently utilizing unlabeled data.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2019</h3>
<ol class="bibliography"><li>

<div id="chen-etal-2019-qtuna">
  
    <span class="title">QTUNA: A Corpus for Understanding How Speakers Use Quantification</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>,
            
          
        
      
        
        
          
          
            
              Silvia Pagliaro,
            
          
        
      
        
        
          
          
            
              Louk Smalbil,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2019, Tokyo</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/W19-8616.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://www.aclweb.org/anthology/attachments/W19-8616.Supplementary_Attachment.pdf" target="_blank">Supplemantary</a>]
  
  
    [<a href="https://github.com/a-quei/qtuna" target="_blank">Data</a>]
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>A prominent strand of work in formal semantics investigates the ways in which human languages quantify over the elements of a set, as when we say “All A are B”, “All except two A are B”, “Only a few of the A are B” and so on. Our aim is to build Natural Language Generation algorithms that mimic humans’ use of quantified expressions. To inform these algorithms, we conducted on a series of elicitation experiments in which human speakers were asked to perform a linguistic task that invites the use of quantified expressions. We discuss how these experiments were conducted and what corpora they gave rise to. We conduct an informal analysis of the corpora, and offer an initial assessment of the challenges that these corpora pose for Natural Language Generation.</p>
  </span>
  
</div>
</li>
<li>

<div id="chen-etal-2019-generating">
  
    <span class="title">Generating Quantified Descriptions of Abstract Visual Scenes</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2019, Tokyo</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/W19-866.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://www.aclweb.org/anthology/attachments/W19-8667.Supplementary_Attachment.pdf" target="_blank">Supplemantary</a>]
  
  
  
  
  
    [<a href="https://github.com/a-quei/quantified-description-generation" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Quantified expressions have always taken up a central position in formal theories of meaning and language use. Yet quantified expressions have so far attracted far less attention from the Natural Language Generation community than, for example, referring expressions. In an attempt to start redressing the balance, we investigate a recently developed corpus in which quantified expressions play a crucial role; the corpus is the result of a carefully controlled elicitation experiment, in which human participants were asked to describe visually presented scenes. Informed by an analysis of this corpus, we propose algorithms that produce computer-generated descriptions of a wider class of visual scenes, and we evaluate the descriptions generated by these algorithms in terms of their correctness, completeness, and human-likeness. We discuss what this exercise can teach us about the nature of quantification and about the challenges posed by the generation of quantified expressions.</p>
  </span>
  
</div>
</li>
<li>

<div id="chen-yao-2019-closer">
  
    <span class="title">A Closer Look at Recent Results of Verb Selection for Data-to-Text NLG</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          and
          
          
            
              <a href="https://www.aclweb.org/anthology/people/j/jin-ge-yao/" target="_blank">Jin-Ge Yao</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2019, Tokyo</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/W19-8622.pdf" target="_blank">PDF</a>]
  
  
    [<a href="https://www.aclweb.org/anthology/attachments/W19-8622.Supplementary_Attachment.pdf" target="_blank">Supplemantary</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Automatic natural language generation systems need to use the contextually-appropriate verbs when describing different kinds of facts or events, which has triggered research interest on verb selection for data-to-text generation. In this paper, we discuss a few limitations of the current task settings and the evaluation metrics. We also provide two simple, efficient, interpretable baseline approaches for statistical selection of trend verbs, which give a strong performance on both previously used evaluation metrics and our new evaluation.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:journals/corr/abs-1901-09672">
  
    <span class="title">Persona-aware Dialogue Generation with Enriched Profile</span>
    <span class="author">
      
        
        
          
          
            
              <a href="https://scholar.google.nl/citations?user=FhU-R7kAAAAJ&amp;hl=en" target="_blank">Yinhe Zheng</a>,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="http://coai.cs.tsinghua.edu.cn/hml/" target="_blank">Minlie Huang</a>,
            
          
        
      
        
        
          
          
            
              Song Liu,
            
          
        
      
        
        
          
          and
          
          
            
              Xuan Zhu
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In NeurIPS 2019 on Conversational AI Workshop, Vancouver</em>
    
    </span>
    <span>
      
      <a style="color:red;">Nomination for Best Paper Award</a>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
    [<a href="http://arxiv.org/abs/1901.09672" target="_blank">arXiv</a>]
  
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Endowing a dialogue system with particular persona is essential to deliver more human-like conversations. However, due to the difficulties of embodying personalities in natural language, this problem is still far from well studied. This paper proposes a novel task of generating dialogue responses conditioned on explicit personal profiles with rich attributes. A dataset is constructed to facilitate the proposed task and a persona-aware dialogue generation model is also introduced. In this model, a structured personal profile (in key-value pairs) is transformed and composed into a representation vector using a persona fusion module, and several different fusion methods are tested. Two techniques, namely \it persona-aware attention and persona-aware bias, are devised to capture and incorporate various persona attributes in the decoding process. Experiments and case studies demonstrate that our model is able to address proper attributes in different contexts.</p>
  </span>
  
</div>
</li>
<li>

<div id="li-etal-2019-dual">
  
    <span class="title">A Dual-Attention Hierarchical Recurrent Neural Network for Dialogue Act Classification</span>
    <span class="author">
      
        
        
          
          
            
              <a href="https://ruizheliuoa.github.io/" target="_blank">Ruizhe Li</a>,
            
          
        
      
        
        
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>,
            
          
        
      
        
        
          
          
            
              <a href="https://homepages.abdn.ac.uk/matthew.collinson/pages/" target="_blank">Matthew Collinson</a>,
            
          
        
      
        
        
          
          
            
              <a href="https://scholar.google.nl/citations?user=ZxQFX5EAAAAJ&amp;hl=en" target="_blank">Xiao Li</a>,
            
          
        
      
        
        
          
          and
          
          
            <em>Guanyi Chen</em>
          
        
      
    </span>

    <span class="periodical">
    
      <em>In CoNLL 2019, Hong Kong, China</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/K19-1036.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Recognising dialogue acts (DA) is important for many natural language processing tasks such as dialogue generation and intention recognition. In this paper, we propose a dual-attention hierarchical recurrent neural network for DA classification. Our model is partially inspired by the observation that conversational utterances are normally associated with both a DA and a topic, where the former captures the social act and the latter describes the subject matter. However, such a dependency between DAs and topics has not been utilised by most existing systems for DA classification. With a novel dual task-specific attention mechanism, our model is able, for utterances, to capture information about both DAs and topics, as well as information about the interactions between them. Experimental results show that by modelling topic as an auxiliary task, our model can significantly improve DA classification, yielding better or comparable performance to the state-of-the-art method on three public datasets.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2018</h3>
<ol class="bibliography"><li>

<div id="chen-etal-2018-simplenlg">
  
    <span class="title">SimpleNLG-ZH: a Linguistic Realisation Engine for Mandarin</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2018, Tilburg</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/W18-6506.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
    [<a href="https://github.com/a-quei/simplenlg-zh" target="_blank">Code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We introduce SimpleNLG-ZH, a realisation engine for Mandarin that follows the software design paradigm of SimpleNLG (Gatt and Reiter, 2009). We explain the core grammar (morphology and syntax) and the lexicon of SimpleNLG-ZH, which is very different from English and other languages for which SimpleNLG engines have been built. The system was evaluated by regenerating expressions from a body of test sentences and a corpus of human-authored expressions. Human evaluation was conducted to estimate the quality of regenerated sentences.</p>
  </span>
  
</div>
</li>
<li>

<div id="chen-etal-2018-modelling">
  
    <span class="title">Modelling Pro-drop with the Rational Speech Acts Model</span>
    <span class="author">
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://homepages.abdn.ac.uk/k.vdeemter/pages/" target="_blank">Kees van Deemter</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In INLG 2018, Tilburg</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/W18-6519.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We extend the classic Referring Expressions Generation task by considering zero pronouns in “pro-drop” languages such as Chinese, modelling their use by means of the Bayesian Rational Speech Acts model (Frank and Goodman, 2012). By assuming that highly salient referents are most likely to be referred to by zero pronouns (i.e., pro-drop is more likely for salient referents than the less salient ones), the model offers an attractive explanation of a phenomenon not previously addressed probabilistically.</p>
  </span>
  
</div>
</li>
<li>

<div id="mao-etal-2018-abdn">
  
    <span class="title">ABDN at SemEval-2018 Task 10: Recognising Discriminative Attributes using Context Embeddings and WordNet</span>
    <span class="author">
      
        
        
          
          
            
              <a href="https://maorui.wixsite.com/homepage" target="_blank">Rui Mao</a>,
            
          
        
      
        
        
          
          
            <em>Guanyi Chen</em>,
          
        
      
        
        
          
          
            
              <a href="https://ruizheliuoa.github.io/" target="_blank">Ruizhe Li</a>,
            
          
        
      
        
        
          
          and
          
          
            
              <a href="https://chenghualin.wordpress.com/" target="_blank">Chenghua Lin</a>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In NAACL 2018 on SemEval Workshop, New Orleans</em>
    
    </span>
    <span>
      
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://www.aclweb.org/anthology/S18-1169.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This paper describes the system that we submitted for SemEval-2018 task 10: capturing discriminative attributes. Our system is built upon a simple idea of measuring the attribute word’s similarity with each of the two semantically similar words, based on an extended word embedding method and WordNet. Instead of computing the similarities between the attribute and semantically similar words by using standard word embeddings, we propose a novel method that combines word and context embeddings which can better measure similarities. Our model is simple and effective, which achieves an average F1 score of 0.62 on the test set.</p>
  </span>
  
</div>
</li></ol>


  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2023 Guanyi Chen.
    
    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="http://localhost:4000/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
<script src="http://localhost:4000/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/font-awesome.min.css">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXX-X', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
